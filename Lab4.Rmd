---
title: "CNN Smartphone Sensor Dataset - Andrew Filiberti & Edward Brunton"
output: html_notebook
---

```{r}
#devtools::install_github("rstudio/keras")
```


```{r}
library(keras)
#install_keras()
```

```{r}
x_train_in = read.table(file = "UCI HAR Dataset/train/X_train.txt", sep = "" , header = F , na.strings ="", stringsAsFactors= F)

y_train_in = read.table(file = "UCI HAR Dataset/train/y_train.txt", sep = "" , header = F , na.strings ="", stringsAsFactors= F)

x_test_in = read.table(file = "UCI HAR Dataset/test/X_test.txt", sep = "" , header = F , na.strings ="", stringsAsFactors= F)

y_test_in = read.table(file = "UCI HAR Dataset/test/y_test.txt", sep = "" , header = F , na.strings ="", stringsAsFactors= F)
```

```{r}
head(x_train_in)
```

```{r}
#convert y in useable data
y_test <- y_test_in -1
y_train <- y_train_in -1
y_test<-as.array(y_test[,1])
y_train<-as.array(y_train[,1])
```

```{r}
dim(y_train)
dim(y_test)
```


```{r}
x_train <- (x_train_in +1)/2
x_train <- matrix(unlist(x_train), ncol = 561, byrow = TRUE)
x_train <- array_reshape(x_train,
                        c(nrow(x_train),
                          561,
                          1))
x_test <- (x_test_in + 1)/2
x_test <- matrix(unlist(x_test), ncol = 561, byrow = TRUE)
x_test <- array_reshape(x_test,
                        c(nrow(x_test),
                          561,
                          1))

input_shape <- c(561, 1)
dim(x_train)
dim(x_test)
```

```{r}
input_shape <- c(561,1)
num_classes <-5
head(y_train)
model <- keras_model_sequential() %>%
  layer_conv_1d(filters = 16,
                kernel_size = c(3),
                activation = 'relu',
                input_shape = input_shape) %>% 
  layer_dropout(rate = 0.25) %>% 
  layer_flatten() %>% 
  layer_dense(units = 10,
              activation = 'relu') %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = num_classes,
              activation = 'softmax')
```

```{r}
model %>% compile(
  loss = loss_categorical_crossentropy,
  optimizer = optimizer_adadelta(),
  metrics = c('accuracy')
)
```



```{r}
batch_size <- 128
epochs <- 12

# Train model
model %>% fit(
  x_train, y_train,
  batch_size = batch_size,
  epochs = epochs,
  validation_split = 0.2
)
score <- model %>% evaluate(x_test,
                            y_test)

cat('Test loss: ', score$loss, "\n")
cat('Test accuracy: ', score$acc, "\n")
```


```
a) Description of Model Architecture

  The model that we decided to implement was a convolutional neural network. We used a 1D convolution function because our data is 1-dimensional. We set the number of filters to 16, and used a kernel-size of 3. This window is a length of 3 centered on each sample. The function applied was a rectified linear unit activation function. This function turns values to 0 if the sample is < 0, but if > 0 uses it as input (ramp). The dropuout rate was set at 0.25, which means it will downsample it by a factor of 1/4. Since the filers turn our data into 2-dimensions, layer flatten will remove the filter dimension and serilaize the filter outputs into 1-dimension. Layer dense takes the outputs of the previous layer within the kernel size and acts like a perceptron, except with a smaller amount of input data (which makes sense knowing convolution is the idea of the model). We used 10 nodes for this layer. We then down-sampled the data again by 1/2, and applied another dense layer with a softmax function (which is a standard output layer function). 
  
  
b) Evaluation/Results



c) Learning the past 2 weeks
  
  A lot of the learning in the last two weeks had to deal with Convolutional Neural Networks (CNNs). Being that traditional ANNs were created to emulate the human brain, CNNs worked in the same way in that they would take whatever input is fed in, compute using activation functions in the hidden layers do come up with a net input value, and then pass it to the output. The difference is that CNNs use convolution, pooling, and fully-connected layers. This is due to the fact that the neuron structure of CNNs is composed of three dimensions, 
  
```

